# üõ°Ô∏è SecureGPT for Video Understanding  
_A simple guide for using Stanford Health Care's Secure GPT-4o to analyze local video files privately_

**Author:** Hee Jung Choi  
**Lab use only | HIPAA-conscious**

---

### üß† Project Context

This guide was developed at Stanford Medicine to help researchers securely analyze videos using the SHC/SoM deployment of GPT-4o. Since video data may contain patient-sensitive information, this workflow ensures all processing happens **locally**, and only **downsampled video frames** are sent securely to SHC‚Äôs GPT-4o API. The code is adapted from OpenAI‚Äôs cookbook but modified for **HIPAA safety and institutional deployment**.

---

## üìò Overview

This short Python notebook demonstrates how to use Stanford Health Care & Stanford School of Medicine‚Äôs **Secure GPT-4o** deployment to analyze and describe videos **without uploading them to the cloud**. It‚Äôs adapted from [OpenAI's Cookbook](https://github.com/openai/openai-cookbook), but tailored for secure, local workflows.

üéØ **Key benefit**: The videos stay on your **local machine**, which helps **avoid HIPAA violations** by keeping patient data private.

---

## üîß What It Does

- ‚úÖ Sends locally saved video frames (not the full video) to GPT-4o via SHC‚Äôs secure API
- ‚úÖ Downsamples frames to avoid long transfer time
- ‚úÖ Requests a high-level natural-language **description** of the video
- ‚úÖ Displays sample frames inline for sanity check

---

## üöÄ How to Use

1. **Set up your environment**  
   - Python 3.8+
   - `cv2`, `requests`, `base64`, `IPython`

2. **Open the notebook**:  
   [`secure_gpt4o_video_guide.ipynb`](./secure_gpt4o_video_guide.ipynb)

3. **Replace the placeholder API key**  
   In the code cells that define `headers`, replace:
   ```python
   "Ocp-Apim-Subscription-Key": "XXX"
with your valid SHC API key.

4. Edit the video path
Replace this line:

video = cv2.VideoCapture("/path/to/your/video.mov")

with the full local path to your video.

5. Run the notebook

- First, it checks connectivity with GPT-4o.

- Then, it loads and encodes frames from the video.

- Finally, it sends a subset of those frames and prints out a suggested caption/description.


